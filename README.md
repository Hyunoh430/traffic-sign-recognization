# Speed Sign Detection System (YOLOv5 + CNN + TFLite)

End-to-end speed sign recognition pipeline:
1. Detect speed signs using a YOLOv5 grayscale model
2. Crop and preprocess the detection
3. Classify cropped sign using a lightweight CNN (TensorFlow Lite)

---

## ðŸ“ Project Structure

```
project_root/
â”œâ”€â”€ run.py                       # Runs YOLOv5 detection and crops highest-confidence result
â”œâ”€â”€ detect_image_utils.py        # (optional) Contains reusable detect_image() logic
â”œâ”€â”€ 128_128.pt                   # YOLOv5 grayscale model (128x128)
â”œâ”€â”€ image1.jpg                   # Sample input image
â”œâ”€â”€ result_image.jpg             # YOLOv5 result with bounding boxes
â”œâ”€â”€ cropped_result.jpg           # Cropped ROI for CNN input
â”œâ”€â”€ speed_sign_model.h5          # Trained CNN model (Keras)
â”œâ”€â”€ speed_sign_model.tflite      # Quantized TFLite model (optional)
â”œâ”€â”€ train_speed_sign_cnn.py      # CNN training script using grayscale images
â”œâ”€â”€ changing_yaml_to_gray.ipynb  # Notebook for YOLO grayscale config + training
â”œâ”€â”€ /home/hyunoh/train/          # Folder of labeled training images by class
â”‚   â”œâ”€â”€ Maximum_Speed_30/
â”‚   â”œâ”€â”€ Maximum_Speed_40/
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md                    # â† this file
```

---

## ðŸ” Step Overview

### 1. Train YOLOv5 (Grayscale, 128x128)
- Train YOLOv5 with custom data using `changing_yaml_to_gray.ipynb`
- Output model: `128_128.pt`

### 2. Run Detection
```bash
python run.py
```
- Loads `image1.jpg`
- Runs YOLOv5
- Saves:
  - `result_image.jpg` (with bounding box)
  - `cropped_result.jpg` (for CNN input)

### 3. Train CNN Classifier
```bash
python train_speed_sign_cnn.py
```
- Trains CNN using grayscale cropped images (7 classes)
- Saves model as `speed_sign_model.h5`

### 4. (Optional) Convert to TFLite
```python
import tensorflow as tf
model = tf.keras.models.load_model("speed_sign_model.h5")
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open("speed_sign_model.tflite", "wb") as f:
    f.write(tflite_model)
```

---

## ðŸ›  Requirements

```bash
pip install torch torchvision opencv-python tensorflow scikit-learn
```

---
---

## ðŸ§  Full Pipeline Overview

The overall process of hybrid detection is shown below:

![Hybrid Detector Pipeline](images/hybrid_detector.png)

> The pipeline includes grayscale preprocessing, YOLOv5 detection, bounding box mapping, and CNN classification using cropped images.

---

## ðŸ“ˆ YOLOv5 Detection Performance

YOLOv5 was trained on custom grayscale images at 128x128 resolution.

![YOLO Performance](images/yolo_perfor.png)

> Precision: 24.38%, Recall: 21.57%, mAP@0.5: 17.34%, mAP@0.5:0.95: 8.21%

---

## ðŸ” CNN Classification Performance

The CNN classifier was applied to cropped sign images.

![CNN Performance](images/cnn_perfor.png)

> Accuracy: 68.33%, Precision (macro): 59.25%, Recall (macro): 67.99%, F1 Score: 61.25%

---

## ðŸ§¬ Custom CNN Architecture

The structure of the CNN model used for sign classification:

![CNN Architecture](images/custom_cnn_arch.png)

---



## ðŸŽ¯ Goals

- Fast and lightweight speed sign recognition system for embedded devices (e.g., Raspberry Pi)
- YOLOv5 + CNN architecture
- Optimized input size: 128Ã—128 grayscale

---

## ðŸš¦ Future Expansion â€“ Multi-object Detection

In order to enhance real-world applicability, we began extending the detection model to include objects such as traffic lights, pedestrians, and vehicles.

> YOLOv5 was reconfigured to support multiple classes, and relevant datasets were explored and partially integrated. This sets the foundation for transitioning the system from a single-task speed sign detector to a generalized road environment detector.

---

## ðŸ“Œ Notes

- `run.py` avoids `detect.py` and gives full control over detection and post-processing
- CNN model is trained separately using speed sign class folders


